# Nirmaan AI â€“ Communication Scoring Tool

FastAPI + vanilla JS application that scores self-introduction transcripts for the **Nirmaan AI Intern Case Study**. The tool ingests a transcript, evaluates it against the official rubric using rule-based checks plus NLP features, and returns:

- Overall score on a 0â€“100 scale
- Detailed per-criterion scores, weights, and textual feedback
- Keyword hit map for the must-have / good-to-have rubric items

The frontend lets evaluators paste a transcript, optionally add duration (seconds) for accurate WPM, and immediately visualize the rubric results.

---

## ðŸš€ Live Demo

**Frontend (Netlify):** [https://nirmaan-communication-score.netlify.app](https://nirmaan-communication-score.netlify.app)

**Backend API (Railway):** [https://nirmaan-communication-scorer-production.up.railway.app](https://nirmaan-communication-scorer-production.up.railway.app)
- Health check: [/health](https://nirmaan-communication-scorer-production.up.railway.app/health)
- API docs: [/docs](https://nirmaan-communication-scorer-production.up.railway.app/docs)

**GitHub Repository:** [https://github.com/Daanu18/nirmaan-communication-scorer](https://github.com/Daanu18/nirmaan-communication-scorer)

---

## Architecture

| Layer      | Stack / Notes                                                                                                          |
|------------|------------------------------------------------------------------------------------------------------------------------|
| Backend    | FastAPI, Pydantic, SentenceTransformers, LanguageTool, VADER. Endpoint `/score` accepts JSON and returns scoring data. |
| Frontend   | Static HTML/CSS/JS (no build step). Calls FastAPI via `fetch`, renders score cards and keyword badges.                 |
| NLP Assets | `all-MiniLM-L6-v2` for semantic similarity; VADER for sentiment; `language_tool_python` for grammar checks.            |

---

## Scoring Formula

Five rubric criteria are normalized and combined using the official weights (total 100). Each criterion produces feedback plus supporting metrics.

| Criterion (weight)             | How it is scored                                                                                                                                                                                                                                                                 | Max pts |
|--------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------|
| **Content & Structure (40)**   | Salutation quality (0â€“5) + keyword presence (must-have phrases worth 4 pts each, good-to-have worth 2 pts each, scaled to 30) + flow check (0/5) + semantic similarity bonus (0â€“5). The similarity uses sentence embeddings to capture paraphrases. Score capped at 40.            |
| **Speech Rate (10)**           | `wpm = words / (duration_seconds / 60)`. WPM mapped to rubric bands: 111â€“140 â†’ 10 pts (ideal), 81â€“110 or 141â€“160 â†’ 6 pts, â‰¥161 or â‰¤80 â†’ 2 pts.                                                                                                                                  |
| **Language & Grammar (20)**    | Grammar errors per 100 words from LanguageTool mapped to 0â€“10, plus Type-Token Ratio (vocabulary richness) mapped to 0â€“10. Sum capped at 20.                                                                                                                                      |
| **Clarity / Filler Words (15)**| Percentage of filler tokens (um, uh, like, etc.): â‰¤3% â†’ 15 pts, 4â€“6% â†’ 12 pts, 7â€“9% â†’ 9 pts, 10â€“12% â†’ 6 pts, â‰¥13% â†’ 3 pts.                                                                                                                 |
| **Engagement / Positivity (15)** | VADER compound sentiment score: â‰¥0.9 â†’ 15, 0.7â€“0.89 â†’ 12, 0.5â€“0.69 â†’ 9, 0.3â€“0.49 â†’ 6, <0.3 â†’ 3.                                                                                                                                           |

The weighted sum of the normalized criterion scores yields the final 0â€“100 score.

Additional logic:

- Semantic keyword detection augments literal phrase checks using cosine similarity (threshold 0.68) so paraphrased statements still count.
- Flow validation ensures transcripts contain a greeting, identity details, and a closing.
- Output includes filler counts, WPM, sentiment, grammar error rates, and keyword hit maps for quick auditing.

---

## Repository Layout

```
backend/
  main.py          # FastAPI app, schemas, CORS
  scoring.py       # Rubric + NLP scoring logic
  requirements.txt
frontend/
  index.html       # UI
  style.css
  script.js
README.md
DEPLOYMENT_STEPS.md
```

---

## Running Locally (Quick Start)

1. **Clone & enter repo**
   ```bash
   git clone https://github.com/Daanu18/nirmaan-communication-scorer.git
   cd nirmaan-communication-scorer
   ```
2. **Install backend dependencies**
   ```bash
   cd backend
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```
3. **Start the API**
   ```bash
   PORT=${PORT:-8000}
   uvicorn main:app --reload --host 0.0.0.0 --port $PORT
   ```
   - Health check: `GET http://127.0.0.1:8000/health`
   - Docs: `http://127.0.0.1:8000/docs`
4. **Open the frontend**
   - Option A: open `frontend/index.html` directly in a browser.
   - Option B (recommended): serve it via a static server for consistent CORS.
     ```bash
     cd ../frontend
     python3 -m http.server 5500
     ```
     Then browse to `http://127.0.0.1:5500`.
5. **Paste a transcript, optionally set duration (seconds), click â€œScoreâ€.**  
   Use the â€œNew Transcriptâ€ button to clear the form and score another sample.

---

## API Reference

`POST /score`

Request
```jsonc
{
  "transcript": "string (required)",
  "duration_seconds": 85
}
```

Response
```jsonc
{
  "overall_score": 84.32,
  "words": 301,
  "sentences": 21,
  "duration_seconds": 85,
  "wpm": 212.47,
  "criteria": [
    {
      "id": "content_structure",
      "name": "Content & Structure",
      "points": 37.65,
      "max_points": 40,
      "weight": 40,
      "normalized": 0.941,
      "feedback": "...",
      "details": {
        "must_hits": {"name": true, "age": true, "...": true},
        "good_hits": {"origin": false, "...": true}
      }
    },
    ...
  ],
  "keyword_hits": {
    "must": {"name": true, "age": true, "...": true},
    "good": {"origin": false, "...": true}
  }
}
```

---

## Deployment

### Production Deployment

- **Backend:** Deployed on [Railway.app](https://railway.app) using Docker
  - Uses multi-stage Docker build to optimize image size
  - Includes Java runtime for LanguageTool
  - Auto-deploys on git push to `main` branch
  - Environment: Python 3.11, 1GB RAM allocation

- **Frontend:** Deployed on [Netlify](https://netlify.com)
  - Static site hosting with auto-deploy from GitHub
  - Configured to call Railway backend API
  - Base directory: `frontend/`

### Local Development

- The backend command above reads the `PORT` environment variable so it can run on PaaS providers (Render/Railway/Heroku) that inject dynamic ports.
- The frontend automatically detects the API base:
  - When served from `localhost:5500`, it talks to `http://127.0.0.1:8000`.
  - When frontend and backend are on the same origin, it uses the current origin.
  - To point the UI at a different backend (e.g., production API), define `window.__API_BASE__ = "https://api.example.com";` before loading `script.js`.

---

## Submission Checklist

- âœ… Working backend (FastAPI) and frontend (HTML/CSS/JS)
- âœ… Rubric-driven scoring with rule-based + NLP + weighting
- âœ… README with scoring explanation and run instructions
- âœ… `DEPLOYMENT_STEPS.md` documented for evaluators
- âœ… Optional enhancements: semantic keyword matching, keyword badges, reset button
- âœ… Production deployment: Backend on Railway, Frontend on Netlify
- âœ… Error handling and fallback mechanisms for robust operation

---

## Future Enhancements

- Export to PDF / downloadable JSON report
- Named-entity extraction to highlight student name in UI
- Fine-tune thresholds per grade level or speech-length cohort
- Batch processing for multiple transcripts
- Historical score tracking and analytics dashboard

Contributions and suggestions are welcome!

